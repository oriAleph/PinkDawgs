{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## [Load and run a model in Python](https://www.tensorflow.org/lite/guide/inference#load_and_run_a_model_in_python):"
      ],
      "metadata": {
        "id": "wQjENKbpUdI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Running TensorFlow Lite Image Classification Models in Python](https://heartbeat.comet.ml/running-tensorflow-lite-image-classification-models-in-python-92ef44b4cd47)\n",
        "\n",
        "\n",
        "[Testing TensorFlow Lite image classification model](https://thinkmobile.dev/testing-tensorflow-lite-image-classification-model/)\n",
        "\n"
      ],
      "metadata": {
        "id": "XK6F5js-U5YA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0xYQ9U3CMrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "572b4d92-a2b8-4206-a6fb-be747cb46cae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "______Input Details______\n",
            "shape: [  1 224 224   3]\n",
            "type: <class 'numpy.uint8'>\n",
            "\n",
            "______Output Details______\n",
            "shape: [ 1 14]\n",
            "type: <class 'numpy.uint8'>\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(\"______Input Details______\")\n",
        "print(\"shape:\", input_details[0]['shape'])\n",
        "print(\"type:\", input_details[0]['dtype'])\n",
        "print(\"\\n______Output Details______\")\n",
        "print(\"shape:\", output_details[0]['shape'])\n",
        "print(\"type:\", output_details[0]['dtype'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "\n",
        "for file in pathlib.Path('test').iterdir():\n",
        "    \n",
        "    # read and resize the image\n",
        "    img = cv2.imread(r\"{}\".format(file.resolve()))\n",
        "    new_img = cv2.resize(img, (224, 224))\n",
        "    \n",
        "    # input_details[0]['index'] = the index which accepts the input\n",
        "    interpreter.set_tensor(input_details[0]['index'], [new_img])\n",
        "    \n",
        "    # run the inference\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Get prediction results\n",
        "    model_prediction = interpreter.get_tensor(output_details[0]['index'])\n",
        "    print(\"For file {}, the output is {}\".format(file.stem, model_prediction))\n",
        "    print(\"Prediction results shape:\", model_prediction.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6logkK239aCI",
        "outputId": "a1ba499a-8265-4775-a24e-d27fc65704a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For file IMG_0675, the output is [[18 59 21  0  0  1  9 46  1  1 16  9 56 17]]\n",
            "Prediction results shape: (1, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [ImageClassifier API - Run inference in Python: ](https://www.tensorflow.org/lite/inference_with_metadata/task_library/image_classifier#run_inference_in_python)"
      ],
      "metadata": {
        "id": "JTpHC-2IWZd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflite-support"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSyPQ78vWVvD",
        "outputId": "4948e1a9-7ce3-4cdb-fd71-2b65b42a89fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tflite-support\n",
            "  Downloading tflite_support-0.4.3-cp37-cp37m-manylinux2014_x86_64.whl (60.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.9 MB 6.5 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.6.0\n",
            "  Downloading pybind11-2.10.1-py3-none-any.whl (216 kB)\n",
            "\u001b[K     |████████████████████████████████| 216 kB 37.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tflite-support) (1.3.0)\n",
            "Collecting sounddevice>=0.4.4\n",
            "  Downloading sounddevice-0.4.5-py3-none-any.whl (31 kB)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from tflite-support) (1.21.6)\n",
            "Requirement already satisfied: protobuf<4,>=3.18.0 in /usr/local/lib/python3.7/dist-packages (from tflite-support) (3.19.6)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.7/dist-packages (from sounddevice>=0.4.4->tflite-support) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->tflite-support) (2.21)\n",
            "Installing collected packages: sounddevice, pybind11, flatbuffers, tflite-support\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires flatbuffers<2,>=1.12, but you have flatbuffers 22.10.26 which is incompatible.\u001b[0m\n",
            "Successfully installed flatbuffers-22.10.26 pybind11-2.10.1 sounddevice-0.4.5 tflite-support-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from tflite_support.task import vision\n",
        "from tflite_support.task import core\n",
        "from tflite_support.task import processor\n",
        "\n",
        "model_path = 'model.tflite'\n",
        "image_path = 'IMG_0676.jpeg'\n",
        "\n",
        "# Initialization\n",
        "base_options = core.BaseOptions(file_name=model_path)\n",
        "classification_options = processor.ClassificationOptions(max_results=2)\n",
        "options = vision.ImageClassifierOptions(base_options=base_options, classification_options=classification_options)\n",
        "classifier = vision.ImageClassifier.create_from_options(options)\n",
        "\n",
        "# Alternatively, you can create an image classifier in the following manner:\n",
        "# classifier = vision.ImageClassifier.create_from_file(model_path)\n",
        "\n",
        "# Run inference\n",
        "image = vision.TensorImage.create_from_file(image_path)\n",
        "classification_result = classifier.classify(image)\n",
        "\n",
        "print(classification_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip9v7xNwWjmr",
        "outputId": "2d81e33c-fd14-432b-cf8a-fd982491479d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClassificationResult(classifications=[Classifications(categories=[Category(index=2, score=0.48828125, display_name='', category_name='2780 Peg with friction'), Category(index=9, score=0.16015625, display_name='', category_name='3020 brick')], head_index=0, head_name='')])\n"
          ]
        }
      ]
    }
  ]
}